{"share_grad_blobs": {"parameters": ["net", "losses", "param_grads", "namescope", "dont_share_blobs=None", "share_activations=False", "blob_shapes=None", ""], "comments": "''' Implements similar optimization as Torch's shareGradInput(): for the gradients that are passed between layers, share blobs between operators when possible. This yields significant memory savings with deep networks.Returns an optimized protobuf (assign to net._net) "}, "is_grad_blob": {"parameters": ["b"], "comments": "# to handle the auto-split gradients "}, "is_grad_op": {"parameters": ["op"], "comments": ""}, "optimize_inference_for_dag": {"parameters": ["net", "input_blobs", "namescope=\"\""], "comments": ""}, "is_activation_blob": {"parameters": ["b"], "comments": ""}, "estimate_memory_usage": {"parameters": ["protos", "shapes", "types", "devicescope"], "comments": "''' Estimate memory usage of a model. This is an estimate because we assume a single threaded execution and miss some internal memory usage of operators. Only estimates the memory for a given device scope.Also, currently it does not handle correctly if blob sizes vary during execution, as it uses only the final blob size.Returns (total, highwater, by op type) memory allocation in bytes. "}, "split_net": {"parameters": ["proto"], "comments": ""}, "num_bytes": {"parameters": ["blob"], "comments": ""}, "release_blobs_when_used": {"parameters": ["netproto", "dont_free_blobs", "selector_fun=None"], "comments": "''' Insert Free-ops after a blob has been used the last time, so that its memory can be reclaimed. Use this only with efficient caching memory managers (such as CUB, --caffe2_cuda_memory_pool=cub).Blobs used with Alias op won't be freed.@dont_free_blobs:is a set of blobs that should not be freed @selector_fun: optional lambda that return True if blob namecan be released. Use for easy special filtering, likeexcluding blobs with \"loss\" in the name.Returns a new protobuffer. To use with a model, use: model.net._net = memonger.release_blobs_when_used(..) "}, "_find_source_nodes": {"parameters": ["g"], "comments": "''' Return nodes without predecessors ''' "}, "_find_target_nodes": {"parameters": ["g"], "comments": "''' Return nodes without successors ''' "}, "_add_single_target_ifneeded": {"parameters": ["g"], "comments": ""}, "_next_available_idx": {"parameters": ["g"], "comments": ""}, "_get_path": {"parameters": ["pred_list", "dist_list"], "comments": "''' Get the path from nx.bellman_ford()'s output ''' "}, "_get_longest_paths": {"parameters": ["g", "source_nodes"], "comments": "''' Get the longest path for nodes in 'source_nodes' Find with bellman_ford() by setting weight = -1 "}, "_build_tree": {"parameters": ["paths"], "comments": "''' Build a tree for given paths based on common elements. Last elements of all paths are the same, which is the root of the tree. "}, "_compute_tree_height": {"parameters": ["g", "root"], "comments": "''' Compute the heights of the tree for all nodes Height of leaves are 0 "}, "_get_height": {"parameters": ["root"], "comments": ""}, "_sort_tree_leaves": {"parameters": ["g", "root"], "comments": "''' For each node, sort its child nodes based on the height of the nodes. Return the leaf nodes of the tree after sorting. "}, "_get_sorted_leaves": {"parameters": ["root"], "comments": ""}, "topological_sort_traversal_longest_path": {"parameters": ["g"], "comments": "''' The graph 'g' may contain several source nodes (nodes without incoming edge), which could be in any order and still be a valid topological sorting result. We would like to arrange these source nodes so that the average live spans of the computed blobs are shorter. The idea is to sort the source nodes based on the length of their path to the target node so that the one with longer path is used first. This is done by: - Add a single target node if there are multiple target nodes in 'g'. - Find the longest path between each source and the target node. - Convert the longest paths to a tree with the target node being the root and source nodes being the leaves. - Sort the nodes of the tree based on the height of the tree. "}, "topological_sort_traversal": {"parameters": ["g"], "comments": ""}, "compute_ranges": {"parameters": ["linearized_ops", "blob_sizes=None"], "comments": ""}, "is_compatible": {"parameters": ["candidate_range", "assignment", "static_blobs"], "comments": ""}, "compute_blob_assignments": {"parameters": ["assignments"], "comments": ""}, "_get_max_size": {"parameters": ["assignment"], "comments": ""}, "get_memory_usage": {"parameters": ["assignments"], "comments": ""}, "compute_assignments_greedy": {"parameters": ["ranges_sorted", "init_assignments=None"], "comments": ""}, "_get_count": {"parameters": ["assignments"], "comments": "''' Return number of blobs in assignments ''' "}, "compute_assignments_dp": {"parameters": ["ranges_sorted", "init_assignment", "counter=None"], "comments": "''' Compute assignment for blobs in 'ranges_sorted' on top of 'init_assignment' using dynamic programming + recursion.ranges_sorted: blobs sorted by 'used' init_assignment: assignment to start with, blobs in 'ranges_sorted' shouldnot be used in 'init_assignment'Using f(b, k, init) to represent the best assignment for blobs b[0:k] given initial assignment 'init', we have f(b, k, init) = f(b, j, init) + find_best(b[j:k], f(b, j, init)) where j is the index of the last best assignment that is independent of blob b[k - 1] (b[k - 1] is compatible with all assignments in f(b, j, init)), and find_best(b1, init1) gives the best assignment for blobs in 'b1' based on the initial assignment 'init1', and blobs b1[0:-1] should be incompatible with b1[-1]. f(b, len(b), []) gives the best assignment for blobs 'b'.For find_best(b, init), since b[0:-1] are not compatible with b[-1], we could reduce it to a smaller problem to find best assignment for b[0:-1] as find_best(b, init) = min { f(b[0:-1], len(b) - 1, init - x) + [x, b[-1]] for x in init, or f(b[0:-1], len(b) - 1, init) + [b[-1]] } where min{} gives the assignment with minimum memory usage. "}, "_get_compatible_prev": {"parameters": ["candidate_range", "best_assignments", "cur_idx"], "comments": "''' Find closest position k of best_assignments that is independent of candidate_range that candiate_range is compatible with all assignments in best_assignments[k]. Return -1 if not found. "}, "is_compatible_all": {"parameters": ["candidate_range", "assignments"], "comments": "''' return true if compatible for all assignments in assignments ''' "}, "_find_best": {"parameters": ["ranges", "init_assignment", "prev_best_assignment", "counter"], "comments": "''' Find the best assignment for blobs 'ranges' given an initialized assignment 'init_assignment'.Blobs in ranges[0:-1] should be incompatible with blob range[-1]. 'prev_best_assignment': best assignment for blobs in ranges[:-1]By assigning ranges[-1] to each assignment k in 'init_assignment' or in a new assignment, the problem becomes a smaller problem to find the best assignment for ranges[0:-1] given the initial assignment init_assigment[0:k, (k+1):-1]. "}, "get_updated_ranges": {"parameters": ["ranges", "max_live=None"], "comments": "''' Set LiveRange.defined = -1 if it is None Set LiveRange.used = max_live if it is None Set LiveRanee.size = 1 if it is None "}, "_get_max_live": {"parameters": ["ranges"], "comments": ""}, "_update_range": {"parameters": ["x", "max_live", "size"], "comments": ""}, "compute_assignments": {"parameters": ["ranges", "static_blobs", "algo"], "comments": "''' algo: Method used to find assignments (AssignmentAlgorithm.GREEDY or AssignmentAlgorithm.DYNAMIC_PROGRAMMING). AssignmentAlgorithm.DYNAMIC_PROGRAMMING gives optimal solution at the cost of more computation. AssignmentAlgorithm.GREEDY may be better in the case 'blob_sizes' is not provided. "}, "verify_assignments": {"parameters": ["assignments"], "comments": ""}, "compute_interference_graph": {"parameters": ["ops"], "comments": ""}, "apply_assignments": {"parameters": ["net", "blob_assignments"], "comments": ""}, "canonical_name": {"parameters": ["blob"], "comments": ""}, "apply_recurrent_blob_assignments": {"parameters": ["op", "blob_assignments", "canonical_name"], "comments": ""}, "optimize_inference_fast": {"parameters": ["net", "static_blobs"], "comments": ""}, "optimize_interference": {"parameters": ["net", "static_blobs", "ordering_function=topological_sort_traversal", "blob_sizes=None", "algo=AssignmentAlgorithm.GREEDY"], "comments": "\"\"\" ordering_function: topological_sort_traversal ortopological_sort_traversal_longest_path.topological_sort_traversal_longest_path gives betterresults but needs a bit more computation. algo: Method used to find assignments (AssignmentAlgorithm.GREEDY or AssignmentAlgorithm.DYNAMIC_PROGRAMMING). AssignmentAlgorithm.DYNAMIC_PROGRAMMING gives optimal solution at the cost of more computation. AssignmentAlgorithm.GREEDY may be better in the case 'blob_sizes' is not provided. "}, "verify_inplace_blobs": {"parameters": ["net_a", "net_b"], "comments": "\"\"\" Verifies that net_a and net_b have the same in-place blob assignments. Particularly, that memonger did not add an in-place assignment when that did not exist before. "}, "get_inplaces": {"parameters": ["op"], "comments": ""}, "verify_graph_equality": {"parameters": ["net_a", "net_b"], "comments": "\"\"\" Determines if the execution of two graphs are identical. That is, all inputs blobs are mapped to the same output blobs for each operator in their respective positions.This is meant to check the output of memonger with the original graph. It assumes that the nets have same external input and output.O(E) runtime + O(1) amortized cost to hash for python dict "}, "parent_list": {"parameters": ["ops"], "comments": ""}, "blob_nbytes": {"parameters": ["blob"], "comments": ""}, "compute_statistics": {"parameters": ["assignments"], "comments": ""}, "collect_blob_sizes": {"parameters": ["net"], "comments": ""}}